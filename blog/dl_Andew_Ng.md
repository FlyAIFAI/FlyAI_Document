# 深度学习-吴恩达
    教程内容收集整理自网络，如有侵权，请联系删除！
# 目录
## 01.神经网络和深度学习
### 1.第一周 深度学习概论
* [1.1 欢迎](https://static.flyai.com/video/deep-learning-Andew-Ng/1.1welcome.mp4)
* [1.2 什么是神经网络？](https://static.flyai.com/video/deep-learning-Andew-Ng/1.2什么是神经网络？.mp4)
* [1.3 用神经网络进行监督学习](https://static.flyai.com/video/deep-learning-Andew-Ng/1.3用神经网络进行监督学习.mp4)
* [1.4 为什么深度学习会兴起？](https://static.flyai.com/video/deep-learning-Andew-Ng/1.4为什么深度学习会兴起？.mp4)
* [1.5 关于这门课](https://static.flyai.com/video/deep-learning-Andew-Ng/1.5关于这门课.mp4)
* [1.6 课程资源](https://static.flyai.com/video/deep-learning-Andew-Ng/1.6课程资源.mp4)
### 2.第二周 神经网络基础
* [2.1 二分分类](https://static.flyai.com/video/deep-learning-Andew-Ng/2.1二分分类.mp4)
* [2.2 logistic 回归](https://static.flyai.com/video/deep-learning-Andew-Ng/2.2logistic回归.mp4)
* [2.3 logistic 回归损失函数](https://static.flyai.com/video/deep-learning-Andew-Ng/2.3logistic回归损失函数.mp4)
* [2.4 梯度下降法](https://static.flyai.com/video/deep-learning-Andew-Ng/2.4梯度下降法.mp4)
* [2.5 导数](https://static.flyai.com/video/deep-learning-Andew-Ng/2.5导数.mp4)
* [2.6 更多导数的例子](https://static.flyai.com/video/deep-learning-Andew-Ng/2.6更多导数的例子.mp4)
* [2.7 计算图](https://static.flyai.com/video/deep-learning-Andew-Ng/2.7计算图.mp4)
* [2.8 计算图的导数计算](https://static.flyai.com/video/deep-learning-Andew-Ng/2.8计算图的导数计算.mp4)
* [2.9 logistic 回归中的梯度下降法](https://static.flyai.com/video/deep-learning-Andew-Ng/2.9logistic回归中的梯度下降法.mp4)
* [2.10 m 个样本的梯度下降](https://static.flyai.com/video/deep-learning-Andew-Ng/2.10m个样本的梯度下降.mp4)
* [2.11 向量化](https://static.flyai.com/video/deep-learning-Andew-Ng/2.11向量化.mp4)
* [2.12 向量化的更多例子](https://static.flyai.com/video/deep-learning-Andew-Ng/2.12向量化的更多例子.mp4)
* [2.13 向量化 logistic 回归](https://static.flyai.com/video/deep-learning-Andew-Ng/2.13向量化logistic回归.mp4)
* [2.14 向量化 logistic 回归的梯度输出](https://static.flyai.com/video/deep-learning-Andew-Ng/2.14向量化logistic回归的梯度输出.mp4)
* [2.15 Python 中的广播](https://static.flyai.com/video/deep-learning-Andew-Ng/2.15Python中的广播.mp4)
* [2.16 关于 python _ numpy 向量的说明](https://static.flyai.com/video/deep-learning-Andew-Ng/2.16关于python_numpy向量的说明.mp4)
* [2.17 Jupyter _ ipython 笔记本的快速指南](https://static.flyai.com/video/deep-learning-Andew-Ng/2.17Jupyter_ipython笔记本的快速指南.mp4)
* [2.18 （选修）logistic 损失函数的解释](https://static.flyai.com/video/deep-learning-Andew-Ng/2.18（选修）logistic损失函数的解释.mp4)
### 3.第三周 浅层神经网络
* [3.1 神经网络概览](https://static.flyai.com/video/deep-learning-Andew-Ng/3.1神经网络概览.mp4)
* [3.2 神经网络表示](https://static.flyai.com/video/deep-learning-Andew-Ng/3.2神经网络表示.mp4)
* [3.3 计算神经网络的输出](https://static.flyai.com/video/deep-learning-Andew-Ng/3.3计算神经网络的输出.mp4)
* [3.4 多个例子中的向量化](https://static.flyai.com/video/deep-learning-Andew-Ng/3.4多个例子中的向量化.mp4)
* [3.5 向量化实现的解释](https://static.flyai.com/video/deep-learning-Andew-Ng/3.5向量化实现的解释.mp4)
* [3.6 激活函数](https://static.flyai.com/video/deep-learning-Andew-Ng/3.6激活函数.mp4)
* [3.7 为什么需要非线性激活函数？](https://static.flyai.com/video/deep-learning-Andew-Ng/3.7为什么需要非线性激活函数？.mp4)
* [3.8 激活函数的导数](https://static.flyai.com/video/deep-learning-Andew-Ng/3.8激活函数的导数.mp4)
* [3.9 神经网络的梯度下降法](https://static.flyai.com/video/deep-learning-Andew-Ng/3.9神经网络的梯度下降法.mp4)
* [3.11 随机初始化](https://static.flyai.com/video/deep-learning-Andew-Ng/3.11随机初始化.mp4)
### 4.第四周 深层神经网络
* [4.1 深层神经网络](https://static.flyai.com/video/deep-learning-Andew-Ng/4.1深层神经网络.mp4)
* [4.2 前向和反向传播](https://static.flyai.com/video/deep-learning-Andew-Ng/4.2前向和反向传播.mp4)
* [4.3 深层网络中的前向传播](https://static.flyai.com/video/deep-learning-Andew-Ng/4.3深层网络中的前向传播.mp4)
* [4.4 核对矩阵的维数](https://static.flyai.com/video/deep-learning-Andew-Ng/4.4核对矩阵的维数.mp4)
* [4.5 为什么使用深层表示](https://static.flyai.com/video/deep-learning-Andew-Ng/4.5为什么使用深层表示.mp4)
* [4.6 搭建深层神经网络块](https://static.flyai.com/video/deep-learning-Andew-Ng/4.6搭建深层神经网络块.mp4)
* [4.7 参数 VS 超参数](https://static.flyai.com/video/deep-learning-Andew-Ng/4.7参数VS超参数.mp4)
* [4.8 这和大脑有什么关系？](https://static.flyai.com/video/deep-learning-Andew-Ng/4.8这和大脑有什么关系？.mp4)
### 5.人工智能行业大师访谈
* [1. 吴恩达采访 Geoffrey Hinton](https://static.flyai.com/video/deep-learning-Andew-Ng/1.吴恩达采访GeoffreyHinton.mp4)
* [2. 吴恩达采访 Pieter Abbeel](https://static.flyai.com/video/deep-learning-Andew-Ng/2.吴恩达采访PieterAbbeel.mp4)
* [3. 吴恩达采访 Ian Goodfellow](https://static.flyai.com/video/deep-learning-Andew-Ng/3.吴恩达采访IanGoodfellow.mp4)
## 02.改善深层神经网络：超参数调试、正则化以及优化
### 1.第一周 深度学习的实用层面
* [1.1 训练_开发_测试集](https://static.flyai.com/video/deep-learning-Andew-Ng/1.1训练_开发_测试集.mp4)
* [1.2 偏差_方差](https://static.flyai.com/video/deep-learning-Andew-Ng/1.2偏差_方差.mp4)
* [1.3 机器学习基础](https://static.flyai.com/video/deep-learning-Andew-Ng/1.3机器学习基础.mp4)
* [1.4 正则化](https://static.flyai.com/video/deep-learning-Andew-Ng/1.4正则化.mp4)
* [1.5 为什么正则化可以减少过拟合？](https://static.flyai.com/video/deep-learning-Andew-Ng/1.5为什么正则化可以减少过拟合？.mp4)
* [1.6 Dropout 正则化](https://static.flyai.com/video/deep-learning-Andew-Ng/1.6Dropout正则化.mp4)
* [1.7 理解 Dropout](https://static.flyai.com/video/deep-learning-Andew-Ng/1.7理解Dropout.mp4)
* [1.8 其他正则化方法](https://static.flyai.com/video/deep-learning-Andew-Ng/1.8其他正则化方法.mp4)
* [1.9 归一化输入](https://static.flyai.com/video/deep-learning-Andew-Ng/1.9归一化输入.mp4)
* [1.10 梯度消失与梯度爆炸](https://static.flyai.com/video/deep-learning-Andew-Ng/1.10梯度消失与梯度爆炸.mp4)
* [1.11 神经网络的权重初始化](https://static.flyai.com/video/deep-learning-Andew-Ng/1.11神经网络的权重初始化.mp4)
* [1.12 梯度的数值逼近](https://static.flyai.com/video/deep-learning-Andew-Ng/1.12梯度的数值逼近.mp4)
* [1.13 梯度检验](https://static.flyai.com/video/deep-learning-Andew-Ng/1.13梯度检验.mp4)
* [1.14 关于梯度检验实现的注记](https://static.flyai.com/video/deep-learning-Andew-Ng/1.14关于梯度检验实现的注记.mp4)
### 2.第二周 优化算法
* [2.1 Mini-batch 梯度下降法](https://static.flyai.com/video/deep-learning-Andew-Ng/2.1Mini-batch梯度下降法.mp4)
* [2.2 理解 mini-batch 梯度下降法](https://static.flyai.com/video/deep-learning-Andew-Ng/2.2理解mini-batch梯度下降法.mp4)
* [2.3 指数加权平均](https://static.flyai.com/video/deep-learning-Andew-Ng/2.3指数加权平均.mp4)
* [2.4 理解指数加权平均](https://static.flyai.com/video/deep-learning-Andew-Ng/2.4理解指数加权平均.mp4)
* [2.5 指数加权平均的偏差修正](https://static.flyai.com/video/deep-learning-Andew-Ng/2.5指数加权平均的偏差修正.mp4)
* [2.6 动量梯度下降法](https://static.flyai.com/video/deep-learning-Andew-Ng/2.6动量梯度下降法.mp4)
* [2.7 RMSprop](https://static.flyai.com/video/deep-learning-Andew-Ng/2.7RMSprop.mp4)
* [2.8 Adam 优化算法](https://static.flyai.com/video/deep-learning-Andew-Ng/2.8Adam优化算法.mp4)
* [2.9 学习率衰减](https://static.flyai.com/video/deep-learning-Andew-Ng/2.9学习率衰减.mp4)
* [2.10 局部最优的问题](https://static.flyai.com/video/deep-learning-Andew-Ng/2.10局部最优的问题.mp4)
### 3.第三周 超参数调试、Batch正则化和程序框架
* [3.1 调试处理](https://static.flyai.com/video/deep-learning-Andew-Ng/3.1调试处理.mp4)
* [3.2 为超参数选择合适的范围](https://static.flyai.com/video/deep-learning-Andew-Ng/3.2为超参数选择合适的范围.mp4)
* [3.3 超参数训练的实践：Pandas VS Caviar](https://static.flyai.com/video/deep-learning-Andew-Ng/3.3超参数训练的实践：PandasVSCaviar.mp4)
* [3.4 正则化网络的激活函数](https://static.flyai.com/video/deep-learning-Andew-Ng/3.4正则化网络的激活函数.mp4)
* [3.5 将 Batch Norm 拟合进神经网络](https://static.flyai.com/video/deep-learning-Andew-Ng/3.5将BatchNorm拟合进神经网络.mp4)
* [3.6 Batch Norm 为什么奏效？](https://static.flyai.com/video/deep-learning-Andew-Ng/3.6BatchNorm为什么奏效？.mp4)
* [3.7 测试时的 Batch Norm](https://static.flyai.com/video/deep-learning-Andew-Ng/3.7测试时的BatchNorm.mp4)
* [3.8 Softmax 回归](https://static.flyai.com/video/deep-learning-Andew-Ng/3.8Softmax回归.mp4)
* [3.9 训练一个 Softmax 分类器](https://static.flyai.com/video/deep-learning-Andew-Ng/3.9训练一个Softmax分类器.mp4)
* [3.10 深度学习框架](https://static.flyai.com/video/deep-learning-Andew-Ng/3.10深度学习框架.mp4)
* [3.11 TensorFlow](https://static.flyai.com/video/deep-learning-Andew-Ng/3.11TensorFlow.mp4)
### 4.人工智能行业大师访谈
* [1. 吴恩达采访 Yoshua Bengio](https://static.flyai.com/video/deep-learning-Andew-Ng/1.吴恩达采访YoshuaBengio.mp4)
* [2. 吴恩达采访 林元庆](https://static.flyai.com/video/deep-learning-Andew-Ng/2.吴恩达采访林元庆.mp4)
## 03.结构化机器学习项目
### 1.第一周 机器学习（ML）策略（1）
* [1.1 为什么是 ML 策略](https://static.flyai.com/video/deep-learning-Andew-Ng/1.1为什么是ML策略.mp4)
* [1.2 正交化](https://static.flyai.com/video/deep-learning-Andew-Ng/1.2正交化.mp4)
* [1.3 单一数字评估指标](https://static.flyai.com/video/deep-learning-Andew-Ng/1.3单一数字评估指标.mp4)
* [1.4 满足和优化指标](https://static.flyai.com/video/deep-learning-Andew-Ng/1.4满足和优化指标.mp4)
* [1.5 训练_开发_测试集划分](https://static.flyai.com/video/deep-learning-Andew-Ng/1.5训练_开发_测试集划分.mp4)
* [1.6 开发集合测试集的大小](https://static.flyai.com/video/deep-learning-Andew-Ng/1.6开发集合测试集的大小.mp4)
* [1.7 什么时候该改变开发_测试集和指标](https://static.flyai.com/video/deep-learning-Andew-Ng/1.7什么时候该改变开发_测试集和指标.mp4)
* [1.8 为什么是人的表现](https://static.flyai.com/video/deep-learning-Andew-Ng/1.8为什么是人的表现.mp4)
* [1.9 可避免偏差](https://static.flyai.com/video/deep-learning-Andew-Ng/1.9可避免偏差.mp4)
* [1.10 理解人的表现](https://static.flyai.com/video/deep-learning-Andew-Ng/1.10理解人的表现.mp4)
* [1.11 超过人的表现](https://static.flyai.com/video/deep-learning-Andew-Ng/1.11超过人的表现.mp4)
* [1.12 改善你的模型的表现](https://static.flyai.com/video/deep-learning-Andew-Ng/1.12改善你的模型的表现.mp4)
### 2.第一周 机器学习（ML）策略（2）
* [2.1 进行误差分析](https://static.flyai.com/video/deep-learning-Andew-Ng/2.1进行误差分析.mp4)
* [2.2 清除标注错误的数据](https://static.flyai.com/video/deep-learning-Andew-Ng/2.2清除标注错误的数据.mp4)
* [2.3 快速搭建你的第一个系统，并进行迭代](https://static.flyai.com/video/deep-learning-Andew-Ng/2.3快速搭建你的第一个系统并进行迭代.mp4)
* [2.4 在不同的划分上进行训练并测试](https://static.flyai.com/video/deep-learning-Andew-Ng/2.4在不同的划分上进行训练并测试.mp4)
* [2.5 不匹配数据划分的偏差和方差](https://static.flyai.com/video/deep-learning-Andew-Ng/2.5不匹配数据划分的偏差和方差.mp4)
* [2.6 定位数据不匹配](https://static.flyai.com/video/deep-learning-Andew-Ng/2.6定位数据不匹配.mp4)
* [2.7 迁移学习](https://static.flyai.com/video/deep-learning-Andew-Ng/2.7迁移学习.mp4)
* [2.8 多任务学习](https://static.flyai.com/video/deep-learning-Andew-Ng/2.8多任务学习.mp4)
* [2.9 什么是端到端的深度学习](https://static.flyai.com/video/deep-learning-Andew-Ng/2.9什么是端到端的深度学习.mp4)
* [2.10 是否要使用端到端的深度学习](https://static.flyai.com/video/deep-learning-Andew-Ng/2.10是否要使用端到端的深度学习.mp4)
### 3.人工智能行业大师访谈
* [1. 采访 Andrej Karpathy](https://static.flyai.com/video/deep-learning-Andew-Ng/1.采访AndrejKarpathy.mp4)
* [2. 采访 Ruslan Salakhutdinov](https://static.flyai.com/video/deep-learning-Andew-Ng/2.采访RuslanSalakhutdinov.mp4)
## 04.卷积神经网络
### 第一周 卷积神经网络
* [1.1 计算机视觉]()
* [1.2 边缘检测示例]()
* [1.3 更多边缘检测内容]()
* [1.4 Padding]()
* [1.5 卷积步长]()
* [1.6 三维卷积]()
* [1.7 单层卷积网络]()
* [1.8 简单卷积网络示例]()
* [1.9 池化层]()
* [1.10 卷积神经网络示例]()
* [1.11 为什么使用卷积？]()
### 第二周 深度卷积网络：实例探究
* [2.1 为什么要进行实例探究？]()
* [2.2 经典网络]()
* [2.3 残差网络]()
* [2.4 残差网络为什么有用？]()
* [2.5 网络中的网络以及 1×1 卷积]()
* [2.6 谷歌 Inception 网络简介]()
* [2.7 Inception 网络]()
* [2.8 使用开源的实现方案]()
* [2.9 迁移学习]()
* [2.10 数据扩充]()
* [2.11 计算机视觉现状]()
### 第三周 目标检测
* [3.1 目标定位]()
* [3.2 特征点检测]()
* [3.3 目标检测]()
* [3.4 卷积的滑动窗口实现]()
* [3.5 Bounding Box预测]()
* [3.6 交并比]()
* [3.7 非极大值抑制]()
* [3.8 Anchor Boxes]()
* [3.9 YOLO 算法]()
* [3.10 候选区域]()
### 第四周 特殊应用：人脸识别和神经风格转换
* [4.1 什么是人脸识别？]()
* [4.2  One-Shot 学习]()
* [4.3  Siamese 网络]()
* [4.4  Triplet 损失]()
* [4.5  面部验证与二分类]()
* [4.6  什么是神经风格转换？]()
* [4.7  什么是深度卷积网络？]()
* [4.8  代价函数]()
* [4.9  内容代价函数]()
* [4.10  风格代价函数]()
* [4.11 一维到三维推广]()
## 05.序列模型
### 第一周 循环序列模型
* [1.1为什么选择序列模型]()
* [1.2数学符号]()
* [1.3循环神经网络]()
* [1.4通过时间的方向传播]()
* [1.6 语言模型和序列生成]()
* [1.7 对新序列采样]()
* [1.8带有神经网络的梯度消失]()
* [1.9 GRU 单元]()
* [1.10 长短期记忆（LSTM）]()
* [1.11 双向神经网络]()
* [1.12 深层循环神经网络]()
### 第二周 自然语言处理与词嵌入
* [2.1 词汇表征]()
* [2.2 使用词嵌入]()
* [2.3 词嵌入的特性]()
* [2.4 嵌入矩阵]()
* [2.5 学习词嵌入]()
* [2.6 Word2Vec]()
* [2.7 负采样]()
* [2.8 GloVe 词向量]()
* [2.9 情绪分类]()
* [2.10 词嵌入除偏]()
### 第三周 序列模型和注意力机制
* [3.1 基础模型]()
* [3.2 选择最可能的句子]()
* [3.3 定向搜索]()
* [3.4 改进定向搜索]()
* [3.5 定向搜索的误差分析]()
* [3.6 Bleu 得分（选修）]()
* [3.7 注意力模型直观理解]()
* [3.8 注意力模型]()
* [3.9 语音辨识]()
* [3.10 触发字检测]()
* [3.11 结论和致谢]()
